{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014d180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9347/1845964733.py:28: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-cohere package and should be used instead. To use it run `pip install -U :class:`~langchain-cohere` and import as `from :class:`~langchain_cohere import Cohere``.\n",
      "  cohere_llm = Cohere(cohere_api_key=COHERE_API_KEY, model=\"command\")\n",
      "/tmp/ipykernel_9347/1845964733.py:52: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = cohere_llm.predict(formatted_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ **Formatted Output** ğŸ“Œ\n",
      " \n",
      "Here is a summary of the document on Generative Artificial Intelligence (GenAI):\n",
      "\n",
      "This report provides an overview of GenAI, a cutting-edge AI algorithm capable of producing novel content across various formats, including text, audio, video, images, and code. GenAI tools have progressed to human-level performance due to advances in machine learning, large datasets, and increased computing power, leading to their metamorphosis from research prototypes to accessible, easy-to-use production tools. This rapid advancement has sparked enthusiasm among businesses and investors, with generative AI startups raising significantly more capital in 2022 compared to 2020. \n",
      "\n",
      "Here are the three key takeaways from the text:\n",
      "\n",
      "1. Generative Artificial Intelligence (GenAI) tools are becoming increasingly accessible and user-friendly, supercharging business processes and operations, and enabling the creation of new deliverables that were previously impractical due to economic or technological constraints. \n",
      "\n",
      "2. This progress is primarily driven by the emergence of large language models (LLMs), which have seen widespread usage and adoption. \n",
      "\n",
      "3. While GenAI models leverage various statistical and computational techniques across different modalities, the report primarily focuses on LLMs due to their central role in driving the overall usage of generative AI models and their importance\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Step 1: Install required libraries (Run this only once) \n",
    "# !pip install langchain cohere langchain-community google-colab \n",
    " \n",
    "# ğŸš€ Step 2: Import necessary libraries \n",
    "import cohere \n",
    "import getpass \n",
    "from langchain import PromptTemplate \n",
    "from langchain.llms import Cohere \n",
    "# from google.colab import auth \n",
    "# from google.colab import drive \n",
    " \n",
    "\n",
    "file_path = \"GenAI.txt\"  # Change this to your file path \n",
    " \n",
    "try: \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file: \n",
    "        text_content = file.read() \n",
    "    print(\"âœ… File loaded successfully!\") \n",
    "except Exception as e: \n",
    "                                                          \n",
    " \n",
    "    print(\"âŒ Error loading file:\", str(e)) \n",
    " \n",
    "# ğŸš€ Step 5: Set Up Cohere API Key \n",
    "COHERE_API_KEY = getpass.getpass(\"ğŸ”‘ Enter your Cohere API Key: \") \n",
    " \n",
    "# ğŸš€ Step 6: Initialize Cohere Model with LangChain \n",
    "cohere_llm = Cohere(cohere_api_key=COHERE_API_KEY, model=\"command\") \n",
    " \n",
    "# ğŸš€ Step 7: Create a Prompt Template \n",
    "template = \"\"\" \n",
    "You are an AI assistant helping to summarize and analyze a text document. \n",
    "Here is the document content: \n",
    " \n",
    "{text} \n",
    " \n",
    "ï¿½\n",
    "ï¿½ Summary: - Provide a concise summary of the document. \n",
    " \n",
    "ï¿½\n",
    "ï¿½ Key Takeaways: - List 3 important points from the text. \n",
    " \n",
    "ï¿½\n",
    "ï¿½ Sentiment Analysis: - Determine if the sentiment of the document is Positive, Negative, or Neutral. \n",
    "\"\"\" \n",
    " \n",
    "prompt_template = PromptTemplate(input_variables=[\"text\"], template=template) \n",
    " \n",
    "# ğŸš€ Step 8: Format the Prompt and Generate Output \n",
    "formatted_prompt = prompt_template.format(text=text_content) \n",
    " \n",
    "response = cohere_llm.predict(formatted_prompt) \n",
    " \n",
    "# ğŸš€ Step 9: Display the Generated Output \n",
    "print(\"\\nğŸ“Œ **Formatted Output** ğŸ“Œ\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45f730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linux-deep-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
